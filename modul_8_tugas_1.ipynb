{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZLZpate+CF2ASlFtSWPr7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fakhryrama/tugas_celerates/blob/main/modul_8_tugas_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re"
      ],
      "metadata": {
        "id": "VmEKARTNBinL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redaksi_text = \"\"\"\n",
        "Perkenalkan, nama saya Reza Wijaya. Saya berusia 34 tahun dan berprofesi sebagai Senior Data Scientist.\n",
        "Saya memiliki pengalaman profesional selama 8 tahun di industri teknologi dan keuangan, dengan fokus utama menerjemahkan data mentah menjadi insight strategis yang dapat ditindaklanjuti (actionable) untuk mendorong pertumbuhan bisnis.\n",
        "Secara teknis, keahlian inti saya meliputi:\n",
        "Pemrograman & Statistik: Mahir menggunakan Python (beserta library utamanya seperti Pandas, NumPy, dan Scikit-learn), R, dan SQL.\n",
        "Machine Learning & AI: Berpengalaman dalam membangun dan mendeploy model prediktif, mulai dari regresi, klasifikasi (seperti logistic regression dan random forests), hingga deep learning (TensorFlow/Keras) untuk computer vision.\n",
        "Data Visualization & Komunikasi: Mampu menyajikan temuan data yang kompleks secara sederhana dan persuasif kepada stakeholder non-teknis menggunakan Tableau dan Power BI.\n",
        "Selama karir saya, saya telah memimpin beberapa proyek berdampak tinggi. Tiga di antaranya yang paling signifikan adalah:\n",
        "Pengembangan Model Prediksi Churn (Churn Prediction): Membangun model untuk sebuah perusahaan telekomunikasi yang berhasil mengidentifikasi pelanggan berisiko tinggi untuk berhenti berlangganan, yang kemudian digunakan sebagai dasar program retensi dan berhasil meningkatkan retensi pelanggan sebesar 15%.\n",
        "Sistem Deteksi Anomali (Fraud Detection) Real-time: Merancang dan mengimplementasikan sistem deteksi penipuan untuk platform fintech, yang berhasil menekan kerugian akibat transaksi palsu hingga 20% per kuartal.\n",
        "Implementasi Recommendation Engine: Memimpin tim untuk membuat mesin rekomendasi produk yang dipersonalisasi untuk sebuah situs e-commerce, yang berkontribusi pada peningkatan conversion rate sebesar 10%.\n",
        "Saya sangat antusias dalam memecahkan masalah bisnis yang kompleks menggunakan data dan pendekatan analitis.\n",
        "\"\"\"\n",
        "print(\"\\n--- OPSI 2: HASIL EKSTRAKSI OTOMATIS ---\")\n",
        "\n",
        "# Mengekstrak data\n",
        "def extract_data(pattern, text, type_converter=str):\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        try:\n",
        "            return type_converter(match.group(1))\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "# 1. Ekstrak data tunggal\n",
        "nama = extract_data(r\"nama saya ([\\w\\s]+)\\.\", redaksi_text)\n",
        "usia = extract_data(r\"berusia (\\d+) tahun\", redaksi_text, int)\n",
        "profesi = extract_data(r\"profesi sebagai ([\\w\\s]+)\\.\", redaksi_text)\n",
        "pengalaman = extract_data(r\"(\\d+) tahun di industri\", redaksi_text, int)\n",
        "\n",
        "# 2. Ekstrak daftar keahlian\n",
        "keahlian_section = re.search(r\"meliputi:(.*?)Selama karir saya\", redaksi_text, re.DOTALL | re.MULTILINE).group(1)\n",
        "keahlian_list = re.findall(r\"\\n\\s*(.*?):\", keahlian_section)\n",
        "\n",
        "# 3. Ekstrak daftar proyek\n",
        "proyek_section = re.search(r\"signifikan adalah:(.*?)Saya sangat antusias\", redaksi_text, re.DOTALL | re.MULTILINE).group(1)\n",
        "proyek_list_raw = re.findall(r\"\\n\\s*(.*?):\", proyek_section)\n",
        "proyek_list_cleaned = []\n",
        "for proyek in proyek_list_raw:\n",
        "    proyek_list_cleaned.append(proyek.split(\" (\")[0].strip())\n",
        "\n",
        "# 4. Susun semuanya menjadi dictionary\n",
        "data_otomatis = {\n",
        "    \"nama_lengkap\": nama,\n",
        "    \"usia\": usia,\n",
        "    \"profesi\": profesi,\n",
        "    \"pengalaman_tahun\": pengalaman,\n",
        "    \"keahlian_pemrograman\": keahlian_list,\n",
        "    \"pengalaman_proyek\": proyek_list_cleaned\n",
        "}\n",
        "\n",
        "# 5. Tampilkan sebagai JSON\n",
        "json_output_otomatis = json.dumps(data_otomatis, indent=2, ensure_ascii=False)\n",
        "print(json_output_otomatis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q9zO59LAzNJ",
        "outputId": "15f7fb54-c21c-40af-f68a-b9d667a45c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- OPSI 2: HASIL EKSTRAKSI OTOMATIS ---\n",
            "{\n",
            "  \"nama_lengkap\": \"Reza Wijaya\",\n",
            "  \"usia\": 34,\n",
            "  \"profesi\": \"Senior Data Scientist\",\n",
            "  \"pengalaman_tahun\": 8,\n",
            "  \"keahlian_pemrograman\": [\n",
            "    \"Pemrograman & Statistik\",\n",
            "    \"Machine Learning & AI\",\n",
            "    \"Data Visualization & Komunikasi\"\n",
            "  ],\n",
            "  \"pengalaman_proyek\": [\n",
            "    \"Pengembangan Model Prediksi Churn\",\n",
            "    \"Sistem Deteksi Anomali\",\n",
            "    \"Implementasi Recommendation Engine\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "redaksi_text = \"\"\"\n",
        "Selamat datang di Kopi Aroma Nusantara. Kedai kopi kami beralamat lengkap di Jalan Cikini Raya No. 73, Menteng, Jakarta Pusat. Didirikan sejak tahun 2018 oleh sepasang sahabat, Bima Santosa dan Rina Hartono, kami berkomitmen untuk menyajikan cita rasa kopi asli dari berbagai penjuru Indonesia.\n",
        "Kami buka setiap hari untuk melayani Anda. Jam operasional kami adalah Senin hingga Jumat pukul 07:00 - 21:00 WIB, sedangkan untuk akhir pekan (Sabtu & Minggu), kami buka lebih lama dari pukul 09:00 hingga 22:00 WIB.\n",
        "Kami bangga dengan tiga menu signature kami yang paling banyak dipesan:\n",
        "Es Kopi Susu \"Nusantara\": Perpaduan espresso house blend kami dengan susu segar dan gula aren murni.\n",
        "Manual Brew V60 \"Flores Bajawa\": Menyajikan karakter fruity dan medium body yang khas dari biji kopi Flores.\n",
        "Cascara \"Lembah Baliem\": Teh herbal yang terbuat dari kulit ceri kopi kering dari Wamena, memberikan rasa manis dan menyegarkan.\n",
        "Untuk mendukung kenyamanan pelanggan, baik untuk bekerja (WFC) ataupun sekadar bersantai, kami menyediakan fasilitas lengkap, termasuk Wi-Fi Kencang (High-Speed Wi-Fi), Ruang Privat (Co-working Space) yang dapat dipesan, dan area Outdoor Smoking yang nyaman.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"--- HASIL EKSTRAKSI OTOMATIS ---\")\n",
        "\n",
        "# Mengekstrak data\n",
        "def extract_data(pattern, text, type_converter=str, group_index=1, flags=0):\n",
        "    match = re.search(pattern, text, flags)\n",
        "    if match:\n",
        "        try:\n",
        "            return type_converter(match.group(group_index))\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "# Ekstrak Data\n",
        "nama_toko = extract_data(r\"Selamat datang di (.*?)\\.\", redaksi_text)\n",
        "alamat = extract_data(r\"beralamat lengkap di (.*?)\\.\", redaksi_text)\n",
        "tahun_berdiri = extract_data(r\"Didirikan sejak tahun (\\d{4})\", redaksi_text, int)\n",
        "\n",
        "# Ekstrak Daftar (List)\n",
        "pendiri_string = extract_data(r\"oleh sepasang sahabat, (.*?), kami berkomitmen\", redaksi_text)\n",
        "pendiri_list = pendiri_string.split(\" dan \") if pendiri_string else []\n",
        "\n",
        "# Ekstrak Nested Dictionary (Jam Operasional)\n",
        "jam_weekdays = extract_data(r\"Senin hingga Jumat pukul ([\\d: -]+ WIB)\", redaksi_text)\n",
        "jam_weekend = extract_data(r\"akhir pekan \\(Sabtu & Minggu\\),.*?pukul ([\\d: -]+ WIB)\", redaksi_text)\n",
        "\n",
        "jam_operasional_dict = {\n",
        "    \"weekdays\": jam_weekdays,\n",
        "    \"weekend\": jam_weekend\n",
        "}\n",
        "\n",
        "# Ekstrak Daftar Menu (dari bullet points)\n",
        "menu_section = extract_data(r\"menu signature kami.*?:(.*?)\\nUntuk mendukung\", redaksi_text, flags=re.DOTALL)\n",
        "menu_list = []\n",
        "if menu_section:\n",
        "    menu_list = re.findall(r\"\\n\\s*(.*?):\", menu_section)\n",
        "\n",
        "# Ekstrak Daftar Fasilitas (Pembersihan Teks)\n",
        "fasilitas_match = re.search(\n",
        "    r\"termasuk (.*?)\\s\\(.*?\\),\\s(.*?)\\s\\(.*?\\)\\s.*?, dan area (.*?) yang nyaman\",\n",
        "    redaksi_text\n",
        ")\n",
        "\n",
        "fasilitas_list = []\n",
        "if fasilitas_match:\n",
        "    fasilitas_list = [\n",
        "        fasilitas_match.group(1), # \"Wi-Fi Kencang\"\n",
        "        fasilitas_match.group(2), # \"Ruang Privat\"\n",
        "        fasilitas_match.group(3)  # \"Outdoor Smoking\"\n",
        "    ]\n",
        "\n",
        "# Susun Semua Data ke Dictionary Akhir\n",
        "data_otomatis = {\n",
        "    \"nama_toko\": nama_toko,\n",
        "    \"alamat\": alamat,\n",
        "    \"tahun_berdiri\": tahun_berdiri,\n",
        "    \"pendiri\": pendiri_list,\n",
        "    \"jam_operasional\": jam_operasional_dict,\n",
        "    \"menu_signature\": menu_list,\n",
        "    \"fasilitas_utama\": fasilitas_list\n",
        "}\n",
        "\n",
        "# Tampilkan sebagai String JSON\n",
        "json_output_otomatis = json.dumps(data_otomatis, indent=2, ensure_ascii=False)\n",
        "print(json_output_otomatis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5bvMk95CjIy",
        "outputId": "f7be9486-91d0-4472-bd3c-8e8867bda16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- HASIL EKSTRAKSI OTOMATIS ---\n",
            "{\n",
            "  \"nama_toko\": \"Kopi Aroma Nusantara\",\n",
            "  \"alamat\": \"Jalan Cikini Raya No\",\n",
            "  \"tahun_berdiri\": 2018,\n",
            "  \"pendiri\": [\n",
            "    \"Bima Santosa\",\n",
            "    \"Rina Hartono\"\n",
            "  ],\n",
            "  \"jam_operasional\": {\n",
            "    \"weekdays\": \"07:00 - 21:00 WIB\",\n",
            "    \"weekend\": null\n",
            "  },\n",
            "  \"menu_signature\": [\n",
            "    \"Es Kopi Susu \\\"Nusantara\\\"\",\n",
            "    \"Manual Brew V60 \\\"Flores Bajawa\\\"\",\n",
            "    \"Cascara \\\"Lembah Baliem\\\"\"\n",
            "  ],\n",
            "  \"fasilitas_utama\": [\n",
            "    \"Wi-Fi Kencang\",\n",
            "    \"Ruang Privat\",\n",
            "    \"Outdoor Smoking\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "redaksi_text = \"\"\"\n",
        "TechNova Solutions membuka kesempatan bagi profesional berbakat untuk bergabung sebagai AI Engineer. Posisi full-time ini berlokasi di kantor pusat kami di Jakarta.\n",
        "Kami mencari kandidat dengan pengalaman profesional minimal 3 tahun dalam pengembangan dan implementasi sistem Kecerdasan Buatan skala produksi.\n",
        "Kualifikasi Teknis Wajib:\n",
        "Pemrograman: Mahir menggunakan Python dan library utamanya seperti Pandas dan NumPy.\n",
        "Frameworks: Pengalaman mendalam dengan TensorFlow atau PyTorch untuk membangun model Deep Learning.\n",
        "MLOps & Deployment: Akrab dengan proses MLOps, termasuk containerization menggunakan Docker dan orkestrasi via Kubernetes.\n",
        "Database: Pemahaman yang kuat tentang SQL dan NoSQL.\n",
        "Tanggung Jawab Utama:\n",
        "Merancang, melatih, dan mengevaluasi model Machine Learning, terutama untuk kasus penggunaan Computer Vision dan Natural Language Processing (NLP).\n",
        "Bekerja sama dengan tim Engineering untuk mengintegrasikan model AI yang sudah teruji ke dalam produk utama perusahaan.\n",
        "Melakukan riset dan eksplorasi terhadap teknologi AI terbaru untuk menjaga daya saing solusi kami.\n",
        "Jika Anda bersemangat dalam memecahkan masalah kompleks dengan data, silakan kirimkan lamaran Anda!\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- HASIL EKSTRAKSI OTOMATIS ---\")\n",
        "\n",
        "def extract_data(pattern, text, type_converter=str, group_index=1, flags=0):\n",
        "    match = re.search(pattern, text, flags)\n",
        "    if match:\n",
        "        try:\n",
        "            return type_converter(match.group(group_index))\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "# Ekstrak Data\n",
        "perusahaan = extract_data(r\"^(.*?) membuka\", redaksi_text.strip())\n",
        "posisi = extract_data(r\"bergabung sebagai (.*?)\\.\", redaksi_text)\n",
        "jenis_pekerjaan = extract_data(r\"Posisi (.*?) ini berlokasi\", redaksi_text)\n",
        "lokasi_kantor = extract_data(r\"kantor pusat kami di (.*?)\\.\", redaksi_text)\n",
        "minimal_pengalaman = extract_data(r\"minimal (\\d+) tahun\", redaksi_text, int)\n",
        "\n",
        "# Ekstraksi Keahlian Teknis\n",
        "kualifikasi_block = extract_data(\n",
        "    r\"Kualifikasi Teknis Wajib:(.*?)Tanggung Jawab Utama:\",\n",
        "    redaksi_text,\n",
        "    flags=re.DOTALL\n",
        ")\n",
        "\n",
        "keahlian_list = []\n",
        "if kualifikasi_block:\n",
        "    keahlian_list = re.findall(\n",
        "        r\"(Python|Pandas|NumPy|TensorFlow|PyTorch|Docker|Kubernetes|SQL|NoSQL)\",\n",
        "        kualifikasi_block\n",
        "    )\n",
        "\n",
        "# Ekstraksi Fokus Teknologi\n",
        "fokus_match = re.search(r\"kasus penggunaan (Computer Vision) dan (Natural Language Processing \\(NLP\\))\", redaksi_text)\n",
        "fokus_list = []\n",
        "if fokus_match:\n",
        "    fokus_list = [fokus_match.group(1), fokus_match.group(2)]\n",
        "\n",
        "# Ekstraksi & Peringkasan Tanggung Jawab\n",
        "tanggung_jawab_block = extract_data(\n",
        "    r\"Tanggung Jawab Utama:(.*?)\\nJika Anda\",\n",
        "    redaksi_text,\n",
        "    flags=re.DOTALL\n",
        ")\n",
        "\n",
        "tanggung_jawab_list = []\n",
        "if tanggung_jawab_block:\n",
        "    raw_bullets = re.findall(r\"\\n\\s*([A-Z].*?)\\.\", tanggung_jawab_block, re.DOTALL)\n",
        "\n",
        "    if len(raw_bullets) > 0:\n",
        "        t1_clean = raw_bullets[0].split(\", terutama\")[0]\n",
        "        tanggung_jawab_list.append(t1_clean)\n",
        "\n",
        "    if len(raw_bullets) > 1:\n",
        "        t2_clean = \"Meng\" + raw_bullets[1].split(\" untuk meng\")[1]\n",
        "        t2_clean = t2_clean.replace(\" yang sudah teruji\", \"\").replace(\" utama\", \"\")\n",
        "        tanggung_jawab_list.append(t2_clean)\n",
        "\n",
        "    if len(raw_bullets) > 2:\n",
        "        t3_clean = raw_bullets[2].split(\" dan eksplorasi terhadap \")[0] + \\\n",
        "                   \" \" + \\\n",
        "                   raw_bullets[2].split(\" dan eksplorasi terhadap \")[1].split(\" untuk\")[0]\n",
        "        tanggung_jawab_list.append(t3_clean)\n",
        "\n",
        "\n",
        "# Susun Semua Data ke Dictionary Akhir\n",
        "data_otomatis = {\n",
        "    \"perusahaan\": perusahaan,\n",
        "    \"posisi\": posisi,\n",
        "    \"jenis_pekerjaan\": jenis_pekerjaan,\n",
        "    \"lokasi_kantor\": lokasi_kantor,\n",
        "    \"minimal_pengalaman_tahun\": minimal_pengalaman,\n",
        "    \"keahlian_teknis_wajib\": keahlian_list,\n",
        "    \"fokus_teknologi_utama\": fokus_list,\n",
        "    \"tanggung_jawab_inti\": tanggung_jawab_list\n",
        "}\n",
        "\n",
        "# Tampilkan sebagai String JSON\n",
        "json_output_otomatis = json.dumps(data_otomatis, indent=2, ensure_ascii=False)\n",
        "print(json_output_otomatis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4UXh_pNEiao",
        "outputId": "69da0a2b-6d1f-4904-fd4e-301bb5989e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- HASIL EKSTRAKSI OTOMATIS ---\n",
            "{\n",
            "  \"perusahaan\": \"TechNova Solutions\",\n",
            "  \"posisi\": \"AI Engineer\",\n",
            "  \"jenis_pekerjaan\": \"full-time\",\n",
            "  \"lokasi_kantor\": \"Jakarta\",\n",
            "  \"minimal_pengalaman_tahun\": 3,\n",
            "  \"keahlian_teknis_wajib\": [\n",
            "    \"Python\",\n",
            "    \"Pandas\",\n",
            "    \"NumPy\",\n",
            "    \"TensorFlow\",\n",
            "    \"PyTorch\",\n",
            "    \"Docker\",\n",
            "    \"Kubernetes\",\n",
            "    \"SQL\",\n",
            "    \"NoSQL\"\n",
            "  ],\n",
            "  \"fokus_teknologi_utama\": [\n",
            "    \"Computer Vision\",\n",
            "    \"Natural Language Processing (NLP)\"\n",
            "  ],\n",
            "  \"tanggung_jawab_inti\": [\n",
            "    \"Merancang, melatih, dan mengevaluasi model Machine Learning\",\n",
            "    \"Mengintegrasikan model AI ke dalam produk perusahaan\",\n",
            "    \"Melakukan riset teknologi AI terbaru\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "redaksi_text = \"\"\"\n",
        "Laporan Rekam Medis Pasien: Bapak Antonius Samosir dengan Nomor Rekam Medis (No. RM) 891011.\n",
        "Pasien berusia 55 tahun datang pada tanggal 07 November 2025 dengan keluhan utama sakit kepala hebat (migrain) yang telah berlangsung selama tiga hari terakhir, disertai rasa mual ringan. Hasil pemeriksaan fisik menunjukkan Tekanan Darah tinggi, yaitu 145/95 mmHg.\n",
        "Diagnosis Dokter:\n",
        "Hipertensi (Tekanan Darah Tinggi) Grade 1.\n",
        "Migrain Kronis.\n",
        "Resep Obat: Dokter meresepkan dua jenis obat. Yang pertama adalah Amlodipine 5 mg yang diminum sekali sehari untuk mengontrol tekanan darah. Yang kedua, Paracetamol 500 mg yang diminum hanya saat nyeri migrain kambuh.\n",
        "Pasien dianjurkan untuk kontrol ulang dan mengevaluasi tekanan darahnya dalam waktu dua minggu ke depan, tepatnya pada tanggal 21 November 2025.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- HASIL EKSTRAKSI OTOMATIS ---\")\n",
        "\n",
        "def extract_data(pattern, text, type_converter=str, group_index=1, flags=0):\n",
        "    match = re.search(pattern, text, flags)\n",
        "    if match:\n",
        "        try:\n",
        "            return type_converter(match.group(group_index))\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "# Ekstrak Data Sederhana & Pembersihan\n",
        "nama_pasien = extract_data(r\"Bapak ([\\w\\s]+) dengan\", redaksi_text)\n",
        "nomor_rm = extract_data(r\"\\(No\\. RM\\) ([\\d]+)\\.\", redaksi_text, int)\n",
        "usia = extract_data(r\"berusia (\\d+) tahun\", redaksi_text, int)\n",
        "tgl_kunjungan = extract_data(r\"datang pada tanggal (.*?)(?: dengan|$)\", redaksi_text).strip()\n",
        "tgl_kontrol = extract_data(r\"tepatnya pada tanggal (.*?)\\.\", redaksi_text)\n",
        "\n",
        "# Ekstrak Data untuk Nested Dictionary\n",
        "tekanan_darah = extract_data(r\"yaitu ([\\d\\/]+ mmHg)\", redaksi_text)\n",
        "data_fisik_dict = {\n",
        "    \"tekanan_darah\": tekanan_darah\n",
        "}\n",
        "\n",
        "# Ekstraksi & Pembersihan List Diagnosis\n",
        "diagnosis_block = extract_data(r\"Diagnosis Dokter:(.*?)Resep Obat:\", redaksi_text, flags=re.DOTALL)\n",
        "diagnosis_list = []\n",
        "if diagnosis_block:\n",
        "    raw_items = re.findall(r\"\\n\\s*(.*?)\\.\", diagnosis_block)\n",
        "\n",
        "    for item in raw_items:\n",
        "        if \"(\" in item:\n",
        "            part1 = item.split(\" (\")[0]\n",
        "            part2 = item.split(\") \")[1]\n",
        "            diagnosis_list.append(f\"{part1} {part2}\")\n",
        "        else:\n",
        "            diagnosis_list.append(item)\n",
        "\n",
        "# Ekstraksi & Format Ulang Resep\n",
        "resep_block = extract_data(r\"Resep Obat:(.*?)Pasien dianjurkan\", redaksi_text, flags=re.DOTALL)\n",
        "resep_list = []\n",
        "if resep_block:\n",
        "    matches = re.findall(r\"(.*? mg) yang diminum (.*?)(?: untuk|\\. Yang|\\.|$)\", resep_block)\n",
        "\n",
        "    for match in matches:\n",
        "        obat = match[0].strip()\n",
        "        frekuensi_raw = match[1].strip()\n",
        "\n",
        "        frekuensi_clean = frekuensi_raw\n",
        "        if \"sekali sehari\" in frekuensi_raw:\n",
        "            frekuensi_clean = \"1x sehari\"\n",
        "        elif \"saat nyeri\" in frekuensi_raw:\n",
        "            frekuensi_clean = \"Saat nyeri\"\n",
        "\n",
        "        resep_list.append(f\"{obat} ({frekuensi_clean})\")\n",
        "\n",
        "# Susun Semua Data ke Dictionary Akhir\n",
        "data_otomatis = {\n",
        "    \"nama_pasien\": nama_pasien,\n",
        "    \"nomor_rekam_medis\": nomor_rm,\n",
        "    \"usia\": usia,\n",
        "    \"tanggal_kunjungan\": tgl_kunjungan,\n",
        "    \"data_fisik_kunci\": data_fisik_dict,\n",
        "    \"diagnosis_utama\": diagnosis_list,\n",
        "    \"resep_obat\": resep_list,\n",
        "    \"tanggal_kontrol_berikutnya\": tgl_kontrol\n",
        "}\n",
        "\n",
        "# Tampilkan sebagai String JSON\n",
        "json_output_otomatis = json.dumps(data_otomatis, indent=2, ensure_ascii=False)\n",
        "print(json_output_otomatis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kloDoX0cFgIx",
        "outputId": "80f82de6-8974-4a4e-d4ec-ab3954b7b1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- HASIL EKSTRAKSI OTOMATIS ---\n",
            "{\n",
            "  \"nama_pasien\": \"Antonius Samosir\",\n",
            "  \"nomor_rekam_medis\": 891011,\n",
            "  \"usia\": 55,\n",
            "  \"tanggal_kunjungan\": \"07 November 2025\",\n",
            "  \"data_fisik_kunci\": {\n",
            "    \"tekanan_darah\": \"145/95 mmHg\"\n",
            "  },\n",
            "  \"diagnosis_utama\": [\n",
            "    \"Hipertensi Grade 1\",\n",
            "    \"Migrain Kronis\"\n",
            "  ],\n",
            "  \"resep_obat\": [\n",
            "    \"Dokter meresepkan dua jenis obat. Yang pertama adalah Amlodipine 5 mg (1x sehari)\",\n",
            "    \"mengontrol tekanan darah. Yang kedua, Paracetamol 500 mg (Saat nyeri)\"\n",
            "  ],\n",
            "  \"tanggal_kontrol_berikutnya\": \"21 November 2025\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "redaksi_text = \"\"\"\n",
        "Film drama fiksi ilmiah berjudul \"Batas Waktu\" ini disutradarai oleh Mira Lesmana dan dirilis pada 2024. Film ini dibintangi oleh Reza Rahadian (sebagai karakter Dr. Arya) dan Chelsea Islan (sebagai karakter Elara). Ceritanya berlatar di tahun 2050 dan berkisah tentang seorang ilmuwan yang mencoba memutar kembali waktu 7 hari untuk mencegah bencana global. Durasi total film adalah 1 jam 52 menit. Film ini memenangkan penghargaan Film Terbaik di Festival CineAsia.\n",
        "\"\"\"\n",
        "print(\"--- HASIL EKSTRAKSI OTOMATIS ---\")\n",
        "\n",
        "def extract_data(pattern, text, type_converter=str, group_index=1, flags=0):\n",
        "    match = re.search(pattern, text, flags)\n",
        "    if match:\n",
        "        try:\n",
        "            return type_converter(match.group(group_index))\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "# Ekstraksi Data Sederhana\n",
        "judul_film = extract_data(r'berjudul \"(.*?)\"', redaksi_text)\n",
        "genre_utama = extract_data(r'Film (.*?) berjudul', redaksi_text)\n",
        "tahun_rilis = extract_data(r'dirilis pada (\\d{4})', redaksi_text, int)\n",
        "sutradara = extract_data(r'disutradarai oleh (.*?) dan', redaksi_text)\n",
        "penghargaan = extract_data(r'memenangkan penghargaan (.*?)\\.', redaksi_text)\n",
        "\n",
        "# Konversi Durasi\n",
        "durasi_match = re.search(r'(\\d+) jam (\\d+) menit', redaksi_text)\n",
        "durasi_menit = 0\n",
        "if durasi_match:\n",
        "    jam = int(durasi_match.group(1))\n",
        "    menit = int(durasi_match.group(2))\n",
        "    durasi_menit = (jam * 60) + menit\n",
        "\n",
        "# Ekstraksi & Pembangunan Struktur Aktor\n",
        "aktor_list = []\n",
        "aktor_block = extract_data(r'dibintangi oleh (.*?)\\.', redaksi_text)\n",
        "\n",
        "if aktor_block:\n",
        "    matches = re.findall(r'([\\w\\s]+) \\(sebagai karakter (.*?)\\)', aktor_block)\n",
        "    for match in matches:\n",
        "        nama_aktor = match[0].strip()\n",
        "        peran_aktor = match[1].strip()\n",
        "        aktor_list.append({\n",
        "            \"nama\": nama_aktor,\n",
        "            \"peran\": peran_aktor\n",
        "        })\n",
        "\n",
        "# Susun Semua Data ke Dictionary Akhir\n",
        "data_otomatis = {\n",
        "    \"judul_film\": judul_film,\n",
        "    \"genre_utama\": genre_utama,\n",
        "    \"tahun_rilis\": tahun_rilis,\n",
        "    \"sutradara\": sutradara,\n",
        "    \"durasi_menit\": durasi_menit,\n",
        "    \"aktor_utama\": aktor_list,\n",
        "    \"penghargaan_spesifik\": penghargaan\n",
        "}\n",
        "\n",
        "# Tampilkan sebagai String JSON\n",
        "json_output_otomatis = json.dumps(data_otomatis, indent=2, ensure_ascii=False)\n",
        "print(json_output_otomatis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv21NNJRIGPo",
        "outputId": "1e95f4b3-3709-4c3e-aeb1-6bef1b8ffed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- HASIL EKSTRAKSI OTOMATIS ---\n",
            "{\n",
            "  \"judul_film\": \"Batas Waktu\",\n",
            "  \"genre_utama\": \"drama fiksi ilmiah\",\n",
            "  \"tahun_rilis\": 2024,\n",
            "  \"sutradara\": \"Mira Lesmana\",\n",
            "  \"durasi_menit\": 112,\n",
            "  \"aktor_utama\": [],\n",
            "  \"penghargaan_spesifik\": \"Film Terbaik di Festival CineAsia\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}